{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seulmi0827/fininsight/blob/main/JACE/BERTopic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "8qZ1sJkvRbLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q bertopic\n",
        "!pip install -q bertopic[visualization]"
      ],
      "metadata": {
        "id": "ZoaQl2oyRd08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install g++ openjdk-8-jdk -y\n",
        "!pip install konlpy\n",
        "!pip install mecab-python\n",
        "!apt-get install curl -y\n",
        "!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "sN3n_KP2Rftw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "import os\n",
        "from konlpy.tag import Mecab\n",
        "from umap import UMAP\n",
        "from hdbscan import HDBSCAN\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from bertopic import BERTopic\n",
        "import plotly.graph_objects as go"
      ],
      "metadata": {
        "id": "mv99JJ-rSwkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_total_original_news(df):\n",
        "    total_original_news = len(df)\n",
        "    return total_original_news\n",
        "\n",
        "\n",
        "def set_weekend_news(df):\n",
        "    weekend_news = len(df[df[\"inp_date\"].dt.dayofweek.isin([5, 6])])\n",
        "    return weekend_news\n",
        "\n",
        "\n",
        "def set_weekday_news(df):\n",
        "    weekday_news = len(df) - set_weekend_news(df)\n",
        "    return weekday_news\n",
        "\n",
        "\n",
        "def load_data(file_path):\n",
        "    \"\"\"데이터만 로드하는 함수\"\"\"\n",
        "    # 데이터프레임 로드\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # 날짜 변환\n",
        "    df[\"inp_date\"] = pd.to_datetime(df[\"inp_date\"])\n",
        "\n",
        "    # 기사 수 저장\n",
        "    original_news_count = set_total_original_news(df)\n",
        "    weekend_news_count = set_weekend_news(df)\n",
        "    weekday_news_count = set_weekday_news(df)\n",
        "\n",
        "    # 주말 제거\n",
        "    df = df[~df[\"inp_date\"].dt.dayofweek.isin([5, 6])]\n",
        "\n",
        "    # 날짜 관련 컬럼 추가\n",
        "    df[\"date\"] = df[\"inp_date\"].dt.date\n",
        "    df[\"month\"] = df[\"inp_date\"].dt.to_period(\"M\")\n",
        "    df[\"week\"] = df[\"inp_date\"].dt.to_period(\"W\")\n",
        "\n",
        "    return df, original_news_count, weekend_news_count, weekday_news_count\n",
        "\n",
        "\n",
        "mecab = Mecab()\n",
        "\n",
        "\n",
        "def preprocess(text):\n",
        "    pos_tagged = mecab.pos(text)\n",
        "\n",
        "    filtered = [\n",
        "        word\n",
        "        for word, pos in pos_tagged\n",
        "        if (\n",
        "            pos.startswith(\"NN\")  # 명사\n",
        "            or pos.startswith(\"VV\")  # 동사\n",
        "            or pos.startswith(\"VA\")  # 형용사\n",
        "            or pos == \"MAG\"  # 일반 부사\n",
        "        )\n",
        "        and len(word) > 1  # 1글자 이상만\n",
        "    ]\n",
        "\n",
        "    return filtered\n",
        "\n",
        "\n",
        "def prepare_text_data(df):\n",
        "    \"\"\"텍스트 데이터 전처리 함수\"\"\"\n",
        "    # 텍스트 전처리\n",
        "    df[\"content\"] = df[\"content\"].fillna(\"\").astype(str)\n",
        "    df[\"preprocessed_content\"] = df[\"content\"].apply(lambda x: \" \".join(preprocess(x)))\n",
        "\n",
        "    # 토픽 모델링용 데이터 준비\n",
        "    preprocessed_content = df[\"content\"].apply(preprocess).tolist()\n",
        "\n",
        "    return df, preprocessed_content\n",
        "\n",
        "\n",
        "# 시드 설정\n",
        "SEED = random.randint(0, 1000000)\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "def initialize_topic_model(seed):\n",
        "    umap_model = UMAP(\n",
        "        n_neighbors=15, n_components=5, min_dist=0.0, metric=\"cosine\", random_state=seed\n",
        "    )\n",
        "\n",
        "    hdbscan_model = HDBSCAN(\n",
        "        min_cluster_size=20,\n",
        "        metric=\"euclidean\",\n",
        "        prediction_data=True,\n",
        "        gen_min_span_tree=True,\n",
        "        cluster_selection_method=\"eom\",\n",
        "    )\n",
        "\n",
        "    embedding_model = SentenceTransformer(\"jhgan/ko-sroberta-multitask\")\n",
        "    vectorizer = CountVectorizer(stop_words=None)\n",
        "\n",
        "    return BERTopic(\n",
        "        language=\"korean\",\n",
        "        nr_topics=10,  # 유효 토픽 결정\n",
        "        top_n_words=7,  # 토픽 별 키워드 수 결정\n",
        "        calculate_probabilities=True,\n",
        "        umap_model=umap_model,\n",
        "        hdbscan_model=hdbscan_model,\n",
        "        embedding_model=embedding_model,\n",
        "        vectorizer_model=vectorizer,\n",
        "        verbose=True,\n",
        "    )\n",
        "\n",
        "\n",
        "def run_topic_modeling(preprocessed_content):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"사용중인 디바이스 : \", device)\n",
        "    print()\n",
        "\n",
        "    # 시드 설정\n",
        "    set_seed(SEED)\n",
        "    print(f\"사용중인 시드 : {SEED}\")\n",
        "    print()\n",
        "\n",
        "    topic_model = initialize_topic_model(SEED)\n",
        "    content_for_topic = [\" \".join(doc) for doc in preprocessed_content]\n",
        "    topics, probs = topic_model.fit_transform(content_for_topic)\n",
        "\n",
        "    return topics, probs, topic_model\n",
        "\n",
        "\n",
        "def calculate_basic_stats(df, original_news_count, weekend_news_count, weekday_news_count):\n",
        "    \"\"\"기본 통계 정보 계산\"\"\"\n",
        "    min_date = df[\"inp_date\"].min()\n",
        "    max_date = df[\"inp_date\"].max()\n",
        "    total_days = (max_date - min_date).days + 1\n",
        "\n",
        "    date_range = pd.date_range(start=min_date, end=max_date)\n",
        "    weekend_days = sum(date.weekday() >= 5 for date in date_range)\n",
        "    weekday_days = total_days - weekend_days\n",
        "\n",
        "    return {\n",
        "        \"min_date\": min_date,\n",
        "        \"max_date\": max_date,\n",
        "        \"total_days\": total_days,\n",
        "        \"weekend_days\": weekend_days,\n",
        "        \"weekday_days\": weekday_days,\n",
        "        \"total_news\": original_news_count,\n",
        "        \"weekend_news\": weekend_news_count,\n",
        "        \"weekday_news\": weekday_news_count,\n",
        "    }\n",
        "\n",
        "\n",
        "def analyze_data_distribution(df, original_news_count, weekend_news_count, weekday_news_count, topics=None, topic_model=None):\n",
        "    \"\"\"데이터 분포 및 토픽 분석 결과를 출력하는 함수\"\"\"\n",
        "    # df.attrs에서 파일 경로 가져오기\n",
        "    file_path = df.attrs.get(\"filepath\", \"\")\n",
        "\n",
        "    # 파일 경로에서 파일명 추출하여 타이틀 생성\n",
        "    file_name = os.path.basename(file_path)\n",
        "    title = os.path.splitext(file_name)[0]\n",
        "\n",
        "    print()\n",
        "    print(\"제목:\", title)\n",
        "    print()\n",
        "\n",
        "    # 기본 통계 계산\n",
        "    stats = calculate_basic_stats(df, original_news_count, weekend_news_count, weekday_news_count)\n",
        "\n",
        "    # 주말 날짜 확인\n",
        "    weekend_dates = df[df[\"inp_date\"].dt.dayofweek.isin([5, 6])][\"inp_date\"].dt.date.unique()\n",
        "\n",
        "    print(f\"데이터 기간: {stats['min_date']} ~ {stats['max_date']}\")\n",
        "    print()\n",
        "    print(f\"총 기간: {stats['total_days']}일\")\n",
        "    print(f\"평일 기간: {stats['weekday_days']}일\")\n",
        "    print(f\"주말 기간: {stats['weekend_days']}일\")\n",
        "    print()\n",
        "    print(f\"전체 기사 수: {stats['total_news']}개\")\n",
        "    print(f\"평일 기사 수: {stats['weekday_news']}개\")\n",
        "    print(f\"주말 기사 수: {stats['weekend_news']}개\")\n",
        "    print()\n",
        "    print(\"주말 날짜 10개 까지만 샘플 출력:\")\n",
        "    print(\"\\n\".join([f\"    {date}\" for date in sorted(weekend_dates)[:9]]))\n",
        "\n",
        "    # 각 단위별 통계\n",
        "    date_counts = df[\"date\"].value_counts().sort_index()\n",
        "    week_counts = df[\"week\"].value_counts().sort_index()\n",
        "    month_counts = df[\"month\"].value_counts().sort_index()\n",
        "\n",
        "    # 토픽 모델링 결과 분석\n",
        "    topic_info = topic_model.get_topic_info()\n",
        "    valid_topics = topic_info[topic_info[\"Topic\"] != -1]\n",
        "    noise_info = topic_info[topic_info[\"Topic\"] == -1]\n",
        "\n",
        "    num_topics = valid_topics.shape[0]\n",
        "    filtered_count = len(topics)\n",
        "    noise_count = noise_info[\"Count\"].values[0] if not noise_info.empty else 0\n",
        "    valid_count = filtered_count - noise_count\n",
        "\n",
        "    print(\"\\n=== 토픽 분석 결과 ===\")\n",
        "    print(f\"유효 토픽 수: {num_topics}개\")\n",
        "    print(f\"주말 제거된 기사 수: {filtered_count}개\")\n",
        "    print(f\"노이즈 아웃라이너 기사 수: {noise_count}개\")\n",
        "    print(f\"유효 토픽 기사 수: {valid_count}개\")\n",
        "    print()\n",
        "\n",
        "    print(\"토픽별 기사 분포:\")\n",
        "    result_df = topic_info[[\"Topic\", \"Count\", \"Representation\"]].copy()\n",
        "    result_df[\"비율(%)\"] = (result_df[\"Count\"] / filtered_count * 100).round(2)\n",
        "    print(result_df)\n",
        "\n",
        "    # 날짜별 문서 수 통계\n",
        "    print(\"\\n== 날짜별 문서 수 통계 ==\")\n",
        "    print(f\"평균 문서 수(일별): {date_counts.mean():.2f}\")\n",
        "    print(f\"최소 문서 수(일별): {date_counts.min()} (날짜: {date_counts.idxmin()})\")\n",
        "    print(f\"최대 문서 수(일별): {date_counts.max()} (날짜: {date_counts.idxmax()})\")\n",
        "\n",
        "    # 주별 문서 수 통계\n",
        "    print(\"\\n== 주별 문서 수 통계 ==\")\n",
        "    print(f\"평균 문서 수(주별): {week_counts.mean():.2f}\")\n",
        "    print(f\"최소 문서 수(주별): {week_counts.min()} (주: {week_counts.idxmin()})\")\n",
        "    print(f\"최대 문서 수(주별): {week_counts.max()} (주: {week_counts.idxmax()})\")\n",
        "\n",
        "    # 월별 문서 수 통계\n",
        "    print(\"\\n== 월별 문서 수 통계 ==\")\n",
        "    print(f\"평균 문서 수(월별): {month_counts.mean():.2f}\")\n",
        "    print(f\"최소 문서 수(월별): {month_counts.min()} (월: {month_counts.idxmin()})\")\n",
        "    print(f\"최대 문서 수(월별): {month_counts.max()} (월: {month_counts.idxmax()})\")\n",
        "\n",
        "    # 통계 정보 업데이트\n",
        "    stats.update(\n",
        "        {\n",
        "\n",
        "            \"title\": title,\n",
        "            \"daily_avg\": date_counts.mean(),\n",
        "            \"weekly_avg\": week_counts.mean(),\n",
        "            \"monthly_avg\": month_counts.mean(),\n",
        "            \"filtered_count\": filtered_count,\n",
        "            \"noise_count\": noise_count,\n",
        "            \"valid_count\": valid_count,\n",
        "        }\n",
        "    )\n",
        "\n",
        "    return stats\n",
        "\n",
        "\n",
        "def create_topic_timeseries(\n",
        "    df,\n",
        "    topics,\n",
        "    topic_model,\n",
        "    time_unit=\"day\",\n",
        "    custom_data=None,\n",
        "    stats=None,\n",
        "):\n",
        "    \"\"\"토픽 시계열 시각화 생성\"\"\"\n",
        "    # 토픽 정보 가져오기\n",
        "    topic_info = topic_model.get_topic_info()\n",
        "    all_topics = topic_info[topic_info[\"Topic\"] != -1][\"Topic\"].tolist()\n",
        "\n",
        "    # 통계 정보가 없으면 기본값 설정\n",
        "    if stats is None:\n",
        "        stats = {}\n",
        "\n",
        "    # 기본 통계 정보 추출\n",
        "    title = stats.get(\"title\", 0)\n",
        "    min_date = stats.get(\"min_date\", df[\"inp_date\"].min())\n",
        "    max_date = stats.get(\"max_date\", df[\"inp_date\"].max())\n",
        "    total_days = stats.get(\"total_days\", (max_date - min_date).days + 1)\n",
        "    weekday_days = stats.get(\"weekday_days\", 0)\n",
        "    weekend_days = stats.get(\"weekend_days\", 0)\n",
        "    total_news = stats.get(\"total_news\", 0)\n",
        "    weekday_news = stats.get(\"weekday_news\", 0)\n",
        "    weekend_news = stats.get(\"weekend_news\", 0)\n",
        "    filtered_count = stats.get(\"filtered_count\", 0)\n",
        "    noise_count = stats.get(\"noise_count\", 0)\n",
        "    valid_count = stats.get(\"valid_count\", 0)\n",
        "\n",
        "    # 시간 단위별 평균\n",
        "    daily_avg = stats.get(\"daily_avg\", 0)\n",
        "    weekly_avg = stats.get(\"weekly_avg\", 0)\n",
        "    monthly_avg = stats.get(\"monthly_avg\", 0)\n",
        "\n",
        "    # 색상 팔레트\n",
        "    colors = [\n",
        "        \"#1f77b4\",\n",
        "        \"#ff7f0e\",\n",
        "        \"#2ca02c\",\n",
        "        \"#d62728\",\n",
        "        \"#9467bd\",\n",
        "        \"#8c564b\",\n",
        "        \"#e377c2\",\n",
        "        \"#7f7f7f\",\n",
        "        \"#bcbd22\",\n",
        "        \"#17becf\",\n",
        "        \"#aec7e8\",\n",
        "        \"#ffbb78\",\n",
        "        \"#98df8a\",\n",
        "        \"#ff9896\",\n",
        "        \"#c5b0d5\",\n",
        "        \"#c49c94\",\n",
        "        \"#f7b6d2\",\n",
        "        \"#c7c7c7\",\n",
        "        \"#dbdb8d\",\n",
        "        \"#9edae5\",\n",
        "        \"#636363\",\n",
        "        \"#6baed6\",\n",
        "        \"#fd8d3c\",\n",
        "        \"#74c476\",\n",
        "        \"#969696\",\n",
        "        \"#3182bd\",\n",
        "        \"#e6550d\",\n",
        "        \"#31a354\",\n",
        "        \"#756bb1\",\n",
        "        \"#de2d26\",\n",
        "    ]\n",
        "\n",
        "    # Figure 생성\n",
        "    fig = go.Figure()\n",
        "\n",
        "    def add_topic_trace(topic_data, topic_id, time_unit_label, marker_size=6):\n",
        "        \"\"\"토픽별 trace 추가\"\"\"\n",
        "        topic_words = [word for word, _ in topic_model.get_topic(topic_id)][:10]\n",
        "        topic_label = f\"토픽 {topic_id}: {', '.join(topic_words)}\"\n",
        "\n",
        "        fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=topic_data[\"date\"],\n",
        "                y=topic_data[\"count\"],\n",
        "                mode=\"lines+markers\",\n",
        "                name=topic_label,\n",
        "                line=dict(color=colors[i % len(colors)]),\n",
        "                marker=dict(size=marker_size),\n",
        "                hovertemplate=f\"<b>%{{text}}</b><br>{time_unit_label}: %{{x|%Y-%m-%d}}<br>문서 수: %{{y}}<extra></extra>\",\n",
        "                text=[topic_label] * len(topic_data),\n",
        "            )\n",
        "        )\n",
        "\n",
        "    def create_title_text(time_unit):\n",
        "        \"\"\"타이틀 텍스트 생성\"\"\"\n",
        "        title_text = f\"{title} 토픽분석 ({time_unit}단위)<br>\"\n",
        "        title_text += f\"<sup>기간: {min_date.strftime('%Y-%m-%d')} ~ {max_date.strftime('%Y-%m-%d')} (총기간 : {total_days}일 | (평일: {weekday_days}일 | 주말: {weekend_days}일)</sup><br>\"\n",
        "        title_text += f\"<sup>문서: 전체 {total_news}개 | 평일 {weekday_news}개 | 주말 {weekend_news}개</sup><br>\"\n",
        "        title_text += f\"<sup>문서: 유효 {valid_count}개 ({valid_count/filtered_count:.1%}) | 노이즈 아웃라이너 {noise_count}개 ({noise_count/filtered_count:.1%})</sup><br>\"\n",
        "        # title_text += f\"<sup>일평균: {daily_avg:.1f}개 | 주평균: {weekly_avg:.1f}개 | 월평균: {monthly_avg:.1f}개</sup>\"\n",
        "        return title_text\n",
        "\n",
        "    def update_layout(title_text, xaxis_title):\n",
        "        \"\"\"레이아웃 업데이트\"\"\"\n",
        "        fig.update_layout(\n",
        "            title={\n",
        "                \"text\": title_text,\n",
        "                \"y\": 0.95,\n",
        "                \"x\": 0.5,\n",
        "                \"xanchor\": \"center\",\n",
        "                \"yanchor\": \"top\",\n",
        "                \"font\": {\"size\": 20, \"color\": \"#1f1f1f\"},\n",
        "            },\n",
        "            xaxis=dict(title=xaxis_title, tickformat=\"%Y-%m-%d\", gridcolor=\"lightgray\"),\n",
        "            yaxis=dict(title=\"문서 수\", gridcolor=\"lightgray\"),\n",
        "            legend=dict(title=\"토픽\", orientation=\"v\"),\n",
        "            hovermode=\"closest\",\n",
        "            plot_bgcolor=\"white\",\n",
        "        )\n",
        "\n",
        "    if time_unit == \"day\":\n",
        "        # 일별 분석\n",
        "        topic_df = pd.DataFrame({\"date\": df[\"inp_date\"].dt.date, \"topic\": topics})\n",
        "        daily_counts = (\n",
        "            topic_df.groupby([\"date\", \"topic\"]).size().reset_index(name=\"count\")\n",
        "        )\n",
        "\n",
        "        for i, topic_id in enumerate(all_topics):\n",
        "            topic_data = daily_counts[daily_counts[\"topic\"] == topic_id]\n",
        "            add_topic_trace(topic_data, topic_id, \"날짜\", 6)\n",
        "\n",
        "        title_text = create_title_text(\"일\")\n",
        "        update_layout(title_text, \"날짜\")\n",
        "\n",
        "    elif time_unit == \"week\":\n",
        "        # 주별 분석\n",
        "        if custom_data is None:\n",
        "            df_with_topics = df.copy()\n",
        "            df_with_topics[\"topic_id\"] = topics\n",
        "            df_with_topics[\"date\"] = (\n",
        "                df_with_topics[\"inp_date\"]\n",
        "                .dt.to_period(\"W-SAT\")\n",
        "                .apply(lambda r: r.start_time)\n",
        "            )\n",
        "            weekly_data = (\n",
        "                df_with_topics.groupby([\"date\", \"topic_id\"])\n",
        "                .size()\n",
        "                .reset_index(name=\"count\")\n",
        "            )\n",
        "        else:\n",
        "            weekly_data = custom_data.reset_index()\n",
        "\n",
        "        for i, topic_id in enumerate(all_topics):\n",
        "            topic_data = (\n",
        "                weekly_data[weekly_data[\"topic_id\"] == topic_id]\n",
        "                if \"topic_id\" in weekly_data.columns\n",
        "                else None\n",
        "            )\n",
        "            if topic_data is not None and not topic_data.empty:\n",
        "                add_topic_trace(topic_data, topic_id, \"주 시작일\", 8)\n",
        "\n",
        "        title_text = create_title_text(\"주\")\n",
        "        update_layout(title_text, \"주 시작일\")\n",
        "\n",
        "    elif time_unit == \"month\":\n",
        "        # 월별 분석\n",
        "        if custom_data is None:\n",
        "            df_with_topics = df.copy()\n",
        "            df_with_topics[\"topic_id\"] = topics\n",
        "            df_with_topics[\"date\"] = (\n",
        "                df_with_topics[\"inp_date\"]\n",
        "                .dt.to_period(\"M\")\n",
        "                .apply(lambda r: r.start_time)\n",
        "            )\n",
        "            monthly_data = (\n",
        "                df_with_topics.groupby([\"date\", \"topic_id\"])\n",
        "                .size()\n",
        "                .reset_index(name=\"count\")\n",
        "            )\n",
        "        else:\n",
        "            monthly_data = custom_data.reset_index()\n",
        "\n",
        "        for i, topic_id in enumerate(all_topics):\n",
        "            topic_data = (\n",
        "                monthly_data[monthly_data[\"topic_id\"] == topic_id]\n",
        "                if \"topic_id\" in monthly_data.columns\n",
        "                else None\n",
        "            )\n",
        "            if topic_data is not None and not topic_data.empty:\n",
        "                add_topic_trace(topic_data, topic_id, \"월 시작일\", 10)\n",
        "\n",
        "        title_text = create_title_text(\"월\")\n",
        "        update_layout(title_text, \"월 시작일\")\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\n",
        "            \"지원되지 않는 시간 단위입니다. 'day', 'week' 또는 'month'를 사용하세요.\"\n",
        "        )\n",
        "\n",
        "    return fig"
      ],
      "metadata": {
        "id": "waYMQx7OW-uG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터프레임 로드\n",
        "path1 = \"/content/drive/MyDrive/Colab Notebooks/경북산불_10000.csv\"\n",
        "path2 = \"/content/drive/MyDrive/Colab Notebooks/경북산불_20000.csv\"\n",
        "df1 = pd.read_csv(path1)\n",
        "df2 = pd.read_csv(path2)\n",
        "\n",
        "# 데이터프레임 합치기\n",
        "combined_df = pd.concat([df1, df2], ignore_index=True)\n",
        "\n",
        "# 임시 파일로 저장\n",
        "temp_path = \"/content/drive/MyDrive/Colab Notebooks/경북산불.csv\"\n",
        "combined_df.to_csv(temp_path, index=False)"
      ],
      "metadata": {
        "id": "fzlBC1WT5WTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 분석 및 통계 정보 계산\n",
        "path = \"/content/drive/MyDrive/Colab Notebooks/경북산불.csv\"\n",
        "\n",
        "df, original_news_count, weekend_news_count, weekday_news_count = load_data(path)\n",
        "df.attrs[\"filepath\"] = path\n",
        "df, preprocessed_content = prepare_text_data(df)\n",
        "topics, probs, topic_model = run_topic_modeling(preprocessed_content)\n",
        "\n",
        "stats = analyze_data_distribution(\n",
        "    df, original_news_count, weekend_news_count, weekday_news_count, topics, topic_model\n",
        ")\n",
        "\n",
        "# 시계열 시각화 생성\n",
        "daily_fig = create_topic_timeseries(\n",
        "    df, topics, topic_model, time_unit=\"day\", stats=stats\n",
        ")\n",
        "weekly_fig = create_topic_timeseries(\n",
        "    df, topics, topic_model, time_unit=\"week\", stats=stats\n",
        ")\n",
        "monthly_fig = create_topic_timeseries(\n",
        "    df, topics, topic_model, time_unit=\"month\", stats=stats\n",
        ")"
      ],
      "metadata": {
        "id": "HhO7RMmuXAK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시각화 표시\n",
        "daily_fig.show()\n",
        "print()\n",
        "weekly_fig.show()\n",
        "# print()\n",
        "# monthly_fig.show()"
      ],
      "metadata": {
        "id": "y-rWM_SkRqCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 분석 및 통계 정보 계산\n",
        "path = \"/content/drive/MyDrive/Colab Notebooks/전남소멸_10000.csv\"\n",
        "\n",
        "df, original_news_count, weekend_news_count, weekday_news_count = load_data(path)\n",
        "df.attrs[\"filepath\"] = path\n",
        "df, preprocessed_content = prepare_text_data(df)\n",
        "topics, probs, topic_model = run_topic_modeling(preprocessed_content)\n",
        "\n",
        "stats = analyze_data_distribution(\n",
        "    df, original_news_count, weekend_news_count, weekday_news_count, topics, topic_model\n",
        ")\n",
        "\n",
        "# 시계열 시각화 생성\n",
        "daily_fig = create_topic_timeseries(\n",
        "    df, topics, topic_model, time_unit=\"day\", stats=stats\n",
        ")\n",
        "weekly_fig = create_topic_timeseries(\n",
        "    df, topics, topic_model, time_unit=\"week\", stats=stats\n",
        ")\n",
        "monthly_fig = create_topic_timeseries(\n",
        "    df, topics, topic_model, time_unit=\"month\", stats=stats\n",
        ")"
      ],
      "metadata": {
        "id": "UVSBVP4bbMaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "weekly_fig.show()\n",
        "print()\n",
        "monthly_fig.show()"
      ],
      "metadata": {
        "id": "ccrJb5vpbbDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KtJyvDm5cK7D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}